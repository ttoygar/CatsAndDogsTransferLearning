{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning_Cats_Dogs_PREPROCESSING.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1tHH3Dwp-4na8kRsUrZ2vOrCBaWtcnWcw",
      "authorship_tag": "ABX9TyMHpSPauH4ApAr8hOcVTk7p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttoygar/CatsAndDogsTransferLearning/blob/main/Transfer_Learning_Cats_Dogs_PREPROCESSING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PREPROCESSING"
      ],
      "metadata": {
        "id": "L_tCEgkeqStz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from skimage.transform import resize as sk_resize\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "OZhqTONiTGOi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATADIR = \"/content/drive/MyDrive/DATASCI/kagglecatsanddogs/PetImages\"\n",
        "CATEGORIES = (\"Dog\",\"Cat\")\n",
        "IMG_SIZE= 64 \n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "YgoJzkgfrnul"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_minmax(x):\n",
        "    return (x-x.min())/(x.max()-x.min())"
      ],
      "metadata": {
        "id": "MhsM-2P-4rYd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    error_amount=0\n",
        "    errors = []\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        label_index = CATEGORIES.index(category) # Dog:0 , Cat:1\n",
        "        for img in tqdm(os.listdir(path)):\n",
        "            try:\n",
        "                img = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR) #, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Resizing\n",
        "                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "                # img_array = sk_resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                # img_array = np.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "\n",
        "                # Converting to RGB\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # Normalization\n",
        "                # img_array = img_array / 255.0\n",
        "                img = normalize_minmax(img)\n",
        "\n",
        "                training_data.append([img, label_index])\n",
        "            except Exception as e:\n",
        "                error_amount +=1\n",
        "                errors.append(e)\n",
        "                pass\n",
        "    print(\"Number of errors:\",error_amount)\n",
        "    # print(\"Errors:\", errors)\n",
        "\n",
        "create_training_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvlmoDaYj0wR",
        "outputId": "38ac3ca4-8f16-461c-f7b2-eed061840ce4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12500/12500 [01:39<00:00, 125.51it/s]\n",
            "  9%|▉         | 1150/12500 [00:22<01:10, 161.75it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
            "  \n",
            "100%|██████████| 12500/12500 [01:44<00:00, 119.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of errors: 54\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(training_data)"
      ],
      "metadata": {
        "id": "lQpL0G7qFxiv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)"
      ],
      "metadata": {
        "id": "M6I_4ygtknsb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a way to split the data\n",
        "# This is unused\n",
        "\n",
        "# First Split\n",
        "# X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=46)\n",
        "\n",
        "# Second split\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.15, random_state=46)"
      ],
      "metadata": {
        "id": "BQZzFoH5IgS0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is another way to split the data.\n",
        "\n",
        "X_train = X[:17500]\n",
        "y_train = y[:17500]\n",
        "\n",
        "X_test = X[17500:21250]\n",
        "y_test = y[17500:21250]\n",
        "\n",
        "X_val = X[21250:]\n",
        "y_val = y[21250:]"
      ],
      "metadata": {
        "id": "rxr4oJtj_zdn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train) #.reshape(-1, IMG_SIZE, IMG_SIZE, 3) # 1 for grayscale, 3 for RGB/BGR\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)"
      ],
      "metadata": {
        "id": "hS8b4R1f_SEa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyNk6w0MGIie",
        "outputId": "2e359c3a-9d9a-4b07-ff91-5295a8577902"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickle Dumping\n",
        "\n",
        "dataset_dict = {\n",
        "    \"X_train\": X_train, \n",
        "    \"X_test\": X_test, \n",
        "    \"X_val\": X_val, \n",
        "    \"y_train\": y_train, \n",
        "    \"y_test\": y_test, \n",
        "    \"y_val\": y_val\n",
        "}\n",
        "\n",
        "with open(os.path.join(DATADIR, \"catsndogs.pickle\"),\"wb\") as file:\n",
        "    pickle.dump(dataset_dict, file)\n"
      ],
      "metadata": {
        "id": "jgb2SLuFknvQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pickle Loading\n",
        "\n",
        "# with open(os.path.join(DATADIR, \"catsndogs.pickle\"),\"rb\") as f:\n",
        "#     X_train, y_train, X_val, y_val, X_test, y_test = pickle.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "VIWvZ_74oY3N"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}